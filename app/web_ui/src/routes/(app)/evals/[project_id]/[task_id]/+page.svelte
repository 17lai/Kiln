<script lang="ts">
  import AppPage from "../../../app_page.svelte"
  import EmptyEvaluator from "./empty_eval.svelte"
  import type { Eval, TaskRunConfig } from "$lib/types"
  import { client } from "$lib/api_client"
  import { KilnError, createKilnError } from "$lib/utils/error_handlers"
  import { onMount, tick } from "svelte"
  import { goto } from "$app/navigation"
  import { page } from "$app/stores"
  import {
    model_info,
    load_model_info,
    model_name,
    prompt_name_from_id,
    current_task_prompts,
  } from "$lib/stores"
  import { prompt_link } from "$lib/utils/link_builder"

  $: project_id = $page.params.project_id
  $: task_id = $page.params.task_id

  let evals: Eval[] | null = null
  let evals_error: KilnError | null = null
  let evals_loading = true

  $: is_empty = !evals || evals.length == 0

  onMount(async () => {
    // Wait for params to load
    await tick()
    // Usually cached and fast
    load_model_info()
    // Load the evals and run configs in parallel
    Promise.all([get_evals(), get_run_configs()])
  })

  async function get_evals() {
    try {
      evals_loading = true
      const { data, error } = await client.GET(
        "/api/projects/{project_id}/tasks/{task_id}/evals",
        {
          params: {
            path: {
              project_id,
              task_id,
            },
          },
        },
      )
      if (error) {
        throw error
      }
      evals = data
    } catch (error) {
      evals_error = createKilnError(error)
    } finally {
      evals_loading = false
    }
  }

  let run_configs: TaskRunConfig[] | null = null
  let run_configs_error: KilnError | null = null
  let run_configs_loading = true

  async function get_run_configs() {
    // "/api/projects/{project_id}/tasks/{task_id}/task_run_configs"
    try {
      run_configs_loading = true
      const { data, error } = await client.GET(
        "/api/projects/{project_id}/tasks/{task_id}/task_run_configs",
        {
          params: {
            path: {
              project_id,
              task_id,
            },
          },
        },
      )
      if (error) {
        throw error
      }
      run_configs = data
    } catch (error) {
      run_configs_error = createKilnError(error)
    } finally {
      run_configs_loading = false
    }
  }

  $: loading = evals_loading || run_configs_loading
  $: error = evals_error || run_configs_error
</script>

<AppPage
  title="Evals"
  subtitle="Evaluate task performance. Compare models, prompts, and fine-tunes."
  sub_subtitle={is_empty ? undefined : "Read the Docs"}
  sub_subtitle_link="https://docs.getkiln.ai/docs/evaluations"
  action_buttons={is_empty
    ? []
    : [
        {
          label: "New Evaluator",
          href: `/evals/${project_id}/${task_id}/create_evaluator`,
          primary: true,
        },
      ]}
>
  {#if loading}
    <div class="w-full min-h-[50vh] flex justify-center items-center">
      <div class="loading loading-spinner loading-lg"></div>
    </div>
  {:else if is_empty}
    <div class="flex flex-col items-center justify-center min-h-[60vh]">
      <EmptyEvaluator {project_id} {task_id} />
    </div>
  {:else if error}
    <div
      class="w-full min-h-[50vh] flex flex-col justify-center items-center gap-2"
    >
      <div class="font-medium">Error Loading Evaluators</div>
      <div class="text-error text-sm">
        {error.getMessage() || "An unknown error occurred"}
      </div>
    </div>
  {:else if evals}
    <div class="overflow-x-auto rounded-lg border">
      <table class="table">
        <thead>
          <tr>
            <th>Eval Name</th>
            <th>Description</th>
            <th>Selected Run Method</th>
          </tr>
        </thead>
        <tbody>
          {#each evals as evaluator}
            {@const run_config = run_configs?.find(
              (run_config) => run_config.id === evaluator.current_run_config_id,
            )}
            {@const prompt_href = run_config?.run_config_properties.prompt_id
              ? prompt_link(
                  project_id,
                  task_id,
                  run_config.run_config_properties.prompt_id,
                )
              : undefined}
            {@const prompt_name =
              run_config?.prompt?.name ||
              prompt_name_from_id(
                run_config?.run_config_properties.prompt_id || "",
                $current_task_prompts,
              )}
            <tr
              class="hover cursor-pointer"
              on:click={() => {
                goto(`/evals/${project_id}/${task_id}/${evaluator.id}`)
              }}
            >
              <td> {evaluator.name} </td>
              <td> {evaluator.description} </td>
              <td>
                {#if run_config}
                  <div class="grid grid-cols-[auto_1fr] gap-2 gap-x-4">
                    <div>Model:</div>
                    <div>
                      {model_name(
                        run_config.run_config_properties.model_name,
                        $model_info,
                      )}
                    </div>
                    <div>Prompt:</div>
                    <div>
                      {#if prompt_href}
                        <a href={prompt_href} class="link">{prompt_name}</a>
                      {:else}
                        {prompt_name}
                      {/if}
                    </div>
                  </div>
                {:else}
                  None
                {/if}
              </td>
            </tr>
          {/each}
        </tbody>
      </table>
    </div>
  {/if}
</AppPage>
